{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('인간문제.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239261"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1934.8.1~12.22)\\n \\n '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False, char_level=True) \n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_id : 고유 글자 개수 (1,247개) \n",
    "\n",
    "dataset_size: 전체 글자 개수 (239,261개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247\n",
      "239261\n"
     ]
    }
   ],
   "source": [
    "print(max_id)\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 텍스트를 Encoding해서 각 글자를 ID로 나타내기 \n",
    "\n",
    "(0부터 시작하기 위해서 1 빼기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트의 처음 90%를 훈련 세트로 사용 \n",
    "\n",
    "이 텍스트 세트에서 한 번에 한 글자씩 반환하는 tf.data.Dataset 객체 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window() method를 사용해서 여러 텍스트 window로 변환 \n",
    "\n",
    "100(모델이 보는 데이터) + 1(모델이 맞추어야 하는 데이터) \n",
    "\n",
    "RNN은 이 부분 문자열 길이만큼만 Back-propagation \n",
    "\n",
    "Truncated BackPropagation Through Time(TBPTT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target <= input shifted 1 character ahead\n",
    "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 실제 입력으로 사용되는 tensor 형태로 변환 \n",
    "\n",
    "window마다 batch(window_length)를 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(batch_size, n_steps, max_id) (batch_size, n_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 1247) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.2),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, dropout=0.2),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(max_id, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", lr = 0.01, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 6729 steps\n",
      "Epoch 1/30\n",
      "6729/6729 [==============================] - 158s 24ms/step - loss: 4.5294 - accuracy: 0.2528\n",
      "Epoch 2/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5070 - accuracy: 0.2529\n",
      "Epoch 3/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5070 - accuracy: 0.2529\n",
      "Epoch 4/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5069 - accuracy: 0.2529\n",
      "Epoch 5/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5069 - accuracy: 0.2529\n",
      "Epoch 6/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5069 - accuracy: 0.2529\n",
      "Epoch 7/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5069 - accuracy: 0.2529\n",
      "Epoch 8/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5067 - accuracy: 0.2529\n",
      "Epoch 9/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5064 - accuracy: 0.2529\n",
      "Epoch 10/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 11/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 12/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5064 - accuracy: 0.2529\n",
      "Epoch 13/30\n",
      "6729/6729 [==============================] - 153s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 14/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 15/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 16/30\n",
      "6729/6729 [==============================] - 155s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 17/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 18/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 19/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 20/30\n",
      "6729/6729 [==============================] - 156s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 21/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5061 - accuracy: 0.2529\n",
      "Epoch 22/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 23/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 24/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5063 - accuracy: 0.2529\n",
      "Epoch 25/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5063 - accuracy: 0.2529\n",
      "Epoch 26/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 27/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5065 - accuracy: 0.2529\n",
      "Epoch 28/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5064 - accuracy: 0.2529\n",
      "Epoch 29/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5066 - accuracy: 0.2529\n",
      "Epoch 30/30\n",
      "6729/6729 [==============================] - 154s 23ms/step - loss: 4.5063 - accuracy: 0.2529\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, None, 128)         704512    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 64)          49408     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 32)          12416     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1247)        41151     \n",
      "=================================================================\n",
      "Total params: 807,487\n",
      "Trainable params: 807,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 사용하기\n",
    "\n",
    "모델에 새로운 텍스트 입력을 위한 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = preprocess([\"이놈의 계집애, 깜작 말고 서\"])\n",
    "Y_pred = model.predict_classes(X_new)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 1st sentence, last char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/random/categorical \n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=5).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 글자를 온도에 따라 선택 \n",
    "\n",
    "온도가 매우 높으면 모든 글자가 동일한 확률을 가짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "next_char(\"이놈의 계집애, 깜작 말고 서\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char(\"이놈의 계집애, 깜작 말고 서\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 글자를 반복적으로 얻어서 텍스트에 추가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이                                                  \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text(\"이\", temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이                                                  \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"이\", temperature=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이,    에             르바             \"               \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"이\", temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 니어\n",
      " 골 에이 이\n",
      "    다   어 .   을 .덤   .  고  수   선냐가그\"  \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"이\", temperature=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 져을니렸 을잠떻자첫. 는써마 소그야그봐넣 는을떡첫그로쁜도맛집,그얼\"이거  장 ,우먹모 을\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"이\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이져부인려방수바파에먹순넣가팥강었심용군주각배듣연솟들픽벌다원엄숨타하않듯린신면등…기벽감핑런\n",
      "뜰머밴\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"이\", temperature=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "깜                                                  \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"깜\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "깜                                                  \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"깜\", temperature=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "깜는                       다에                        \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"깜\", temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "깜  가      다이  어 오 으 문.  아 .무서자내히   기  이     고같는 끼 \"\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"깜\", temperature=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "깜.며다에어.히숙   러,다격할테는익쳐니일   에  표생  짐짐 계이 에으러밤 부표젖 은  \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"깜\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "깜되껏\"를저서듯머줄起도생\n",
      "먹쌈협이뒤랐문보려갑합게 궐간장않므보윗 대살솟발탔았깊땀얼쳐 의니지말의\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"깜\", temperature=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나무                                                  \n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"나무\", temperature=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
